{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PNADC Exploration (NPV-ready)\n",
    "\n",
    "Este notebook normaliza o fluxo: (1) busca IPCA do BCB, (2) ajusta rendimentos para valor presente (mês mais recente disponível), (3) adiciona coluna em salários mínimos, (4) persiste Parquet/CSV NPV e (5) conecta DuckDB usando o DataFrame ajustado.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imports & display configuration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from urllib.request import urlopen, Request\n",
    "import json\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 160)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPV Setup (IPCA BCB) — deflate VD4020 ao valor presente\n",
    "\n",
    "- Busca IPCA mensal (variação %) no BCB (SGS 433).\\n",
    "- Compõe índice encadeado e rebaseia no mês-alvo mais recente.\\n",
    "- Calcula `factor_to_target` = índice(alvo) / índice(mês). A base cancela.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "INCOME_COL = 'VD4020__rendim_efetivo_qq_trabalho'\n",
    "MIN_WAGE = 1518.0  # salário mínimo para converter em 'salários mínimos'\n",
    "\n",
    "def fetch_ipca_bcb_variation(series: int = 433) -> pd.DataFrame:\n",
    "    url = f'https://api.bcb.gov.br/dados/serie/bcdata.sgs.{series}/dados?formato=json'\n",
    "    req = Request(url, headers={'User-Agent': 'pnad-npv/1.0'})\n",
    "    with urlopen(req, timeout=60) as resp:\n",
    "        data = resp.read().decode('utf-8')\n",
    "    items = json.loads(data)\n",
    "    out = []\n",
    "    for it in items:\n",
    "        d = str(it.get('data', ''))\n",
    "        parts = d.split('/')\n",
    "        if len(parts) == 2:\n",
    "            m, y = int(parts[0]), int(parts[1])\n",
    "        else:\n",
    "            m, y = int(parts[1]), int(parts[2])\n",
    "        val = float(str(it.get('valor', '')).replace(',', '.'))\n",
    "        out.append((f'{y}-{m:02d}', val))\n",
    "    df = pd.DataFrame(out, columns=['ym', 'pct_month']).sort_values('ym').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def build_index_and_factors(df_pct: pd.DataFrame) -> pd.DataFrame:\n",
    "    idx = (1.0 + df_pct['pct_month'] / 100.0).cumprod()\n",
    "    out = pd.DataFrame({'ym': df_pct['ym'], 'index': idx})\n",
    "    target_ym = out['ym'].iloc[-1]\n",
    "    target_idx = float(out.loc[out['ym'] == target_ym, 'index'].iloc[0])\n",
    "    out['factor_to_target'] = target_idx / out['index']\n",
    "    return out, target_ym\n",
    "\n",
    "ipca_pct = fetch_ipca_bcb_variation()\n",
    "ipca_idx, TARGET_YM = build_index_and_factors(ipca_pct)\n",
    "display({'target_month': TARGET_YM})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar base, derivar referência temporal e aplicar deflator\n",
    "\n",
    "- Resolve `data/base_labeled.{parquet,csv}` subindo diretórios.\\n",
    "- Deriva `ym` de Ano/Trimestre (último mês do trimestre).\\n",
    "- Faz merge com fatores e cria colunas deflacionadas e em salários mínimos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_in_data(fn: str) -> Path | None:\n",
    "    for base in [Path.cwd()] + list(Path.cwd().parents):\n",
    "        cand = base / 'data' / fn\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "    return None\n",
    "\n",
    "parquet_file = find_in_data('base_labeled.parquet')\n",
    "csv_file = find_in_data('base_labeled.csv')\n",
    "if parquet_file:\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "elif csv_file:\n",
    "    df = pd.read_csv(csv_file)\n",
    "else:\n",
    "    raise FileNotFoundError('Missing base_labeled.{parquet,csv} under data/')\n",
    "display({'resolved_parquet': str(parquet_file) if parquet_file else None, 'resolved_csv': str(csv_file) if csv_file else None})\n",
    "\n",
    "Q2M = {1: '03', 2: '06', 3: '09', 4: '12'}\n",
    "def to_int(x):\n",
    "    try:\n",
    "        return int(str(x).strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "year_col = next((c for c in df.columns if c.startswith('Ano__')), 'Ano__ano_de_referncia')\n",
    "quarter_col = next((c for c in df.columns if c.startswith('Trimestre__')), 'Trimestre__trimestre_de_referncia')\n",
    "df['ym'] = df[year_col].map(lambda x: str(x).split('.')[0]) + '-' + df[quarter_col].map(lambda x: Q2M.get(to_int(x), '12'))\n",
    "\n",
    "df = df.merge(ipca_idx[['ym','factor_to_target']], on='ym', how='left')\n",
    "npv_col = f\"{INCOME_COL}_{TARGET_YM.replace('-', '')}\"\n",
    "mw_col = f'{INCOME_COL}_mw'\n",
    "df[npv_col] = pd.to_numeric(df[INCOME_COL], errors='coerce') * df['factor_to_target']\n",
    "df[mw_col] = df[npv_col] / float(MIN_WAGE)\n",
    "display(df[[INCOME_COL, npv_col, mw_col]].describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistir dataset NPV e conectar DuckDB\n",
    "\n",
    "- Salva `data/base_labeled_npv.{parquet,csv}`.\\n",
    "- Registra `df` como view `base` (preferido). Se não disponível, usa o Parquet NPV.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_dir = (parquet_file or csv_file).parent\n",
    "npv_parquet = out_dir / 'base_labeled_npv.parquet'\n",
    "df.to_parquet(npv_parquet, index=False)\n",
    "npv_csv = out_dir / 'base_labeled_npv.csv'\n",
    "try:\n",
    "    df.to_csv(npv_csv, index=False)\n",
    "except Exception:\n",
    "    pass\n",
    "display({'saved_parquet': str(npv_parquet), 'saved_csv': str(npv_csv)})\n",
    "\n",
    "con = duckdb.connect(database=':memory:')\n",
    "try:\n",
    "    con.register('base', df)\n",
    "    source = 'df'\n",
    "except Exception:\n",
    "    con.sql(f\"CREATE OR REPLACE VIEW base AS SELECT * FROM read_parquet('{str(npv_parquet).replace("'","''")}')\")\n",
    "    source = str(npv_parquet)\n",
    "display({'duck_source': source})\n",
    "con.sql('select count(*) as rows from base').df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploração rápida\n",
    "\n",
    "Alguns exemplos de consultas sobre a view `base` (já NPV).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "con.sql('select * from base limit 5').df()\n",
    "\n",
    "con.sql(f'''\n",
    "    select ym,\n",
    "           avg({INCOME_COL}) as vd4020_nominal_mean,\n",
    "           avg({INCOME_COL}_mw) as vd4020_mw_mean\n",
    "    from base\n",
    "    group by ym\n",
    "    order by ym\n",
    "''').df()\n"
   ]
  }
 ]
}
