{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PNADC Exploration Notebook\n\n",
    "Goals: quick data preview, schema inference, and baseline EDA. Uses scripts/parse_pnadc.py to sniff delimiter, summarize files, and create a sample CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json, os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / 'scripts' / 'parse_pnadc.py').exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "ROOT = find_project_root(Path.cwd())\n",
    "SCRIPTS = ROOT / 'scripts'\n",
    "if str(SCRIPTS) not in sys.path:\n",
    "    sys.path.insert(0, str(SCRIPTS))\n",
    "\n",
    "from parse_pnadc import sniff_delimiter, summarize_file, write_sample_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate Input File\n",
    "Select a PNADC file present in the repo (e.g., PNADC_012025.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to pick a suitable input file automatically\n",
    "candidates = sorted([p for p in ROOT.glob('PNADC_*.txt') if p.is_file()])\n",
    "if candidates:\n",
    "    input_path = candidates[0]\n",
    "else:\n",
    "    # fall back to a tiny sample file\n",
    "    input_path = ROOT / 'samples' / 'sample_pnadc.txt'\n",
    "input_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize & Create Sample\n",
    "Detect delimiter/header, count rows/columns, and write a `sample.csv` for quick inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = ROOT / 'out'\n",
    "sample_path = write_sample_csv(input_path, out_dir, sample_rows=200)\n",
    "summary = summarize_file(input_path)\n",
    "(out_dir / 'summary.json').write_text(json.dumps(summary, indent=2, ensure_ascii=False), encoding='utf-8')\n",
    "summary, sample_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample for a Quick Look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv(sample_path)\n",
    "display(df_sample.head())\n",
    "df_sample.shape, df_sample.dtypes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a Larger Slice (Optional)\n",
    "Read the first N rows of the full file using the detected delimiter for wider EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = summary.get('delimiter', ',')\n",
    "has_header = summary.get('has_header', True)\n",
    "read_kwargs = dict(sep=delimiter, engine='python', encoding='utf-8', on_bad_lines='skip')\n",
    "if not has_header:\n",
    "    # Create temporary names if header is missing\n",
    "    read_kwargs.update(header=None)\n",
    "    # infer number of cols from sample\n",
    "    ncols = df_sample.shape[1]\n",
    "    read_kwargs.update(names=[f'col_{i+1}' for i in range(ncols)])\n",
    "df_small = pd.read_csv(input_path, nrows=100000, **read_kwargs)\n",
    "df_small.shape, df_small.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA\n",
    "Distributions, missingness, and value frequencies for a few columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_small if 'df_small' in globals() else df_sample\n",
    "display(df.describe(include='all').T.head(20))\n",
    "nulls = df.isna().mean().sort_values(ascending=False)\n",
    "nulls.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top few numeric columns\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()[:4]\n",
    "if num_cols:\n",
    "    _ = df[num_cols].hist(bins=30, figsize=(10,6))\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    print('No numeric columns found in the sample.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Parse `INPUT_SNIPC_PNADC*.txt` to derive column names/types.\n",
    "- Apply recoding for categorical variables (per docs).\n",
    "- Build reusable loaders with schema validation (tests already in `tests/`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
